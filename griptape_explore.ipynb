{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "209748f5",
   "metadata": {},
   "source": [
    "Just exploring the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98be311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import griptape\n",
    "from griptape.memory.structure import ConversationMemory\n",
    "from griptape.memory.tool import TextToolMemory, BlobToolMemory\n",
    "from griptape.structures import Pipeline\n",
    "from griptape.tasks import ToolkitTask, PromptTask\n",
    "from griptape.tools import WebScraper, TextProcessor, FileManager, RestApiClient\n",
    "from griptape.drivers import OpenAiPromptDriver\n",
    "from griptape.memory.structure import ConversationMemory\n",
    "\n",
    "\n",
    "from griptape import utils\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e00bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tool_memory = TextToolMemory()\n",
    "blob_tool_memory = BlobToolMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13156bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = TextProcessor(\n",
    "    memory={\n",
    "        \"summarize\": {\n",
    "            \"input\": [text_tool_memory]\n",
    "        },\n",
    "        \"search\": {\n",
    "            \"input\": [text_tool_memory]\n",
    "        }\n",
    "    }, verbose = False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22098271",
   "metadata": {},
   "source": [
    "griptape takes JSON schema to describe endpoints, these functions convert OpenAPI spec to the schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "25be3ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   RestApiClient(allowlist=None, denylist=None, name='/search', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='search', description='Search for entities in the Monarch knowledge graph', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Search for entities in the Monarch knowledge graph', 'properties': {'term': {'title': 'Term', 'type': 'string', 'description': 'The ontology term to search for.'}, 'category': {'title': 'Category', 'type': 'string', 'description': 'A single category to search within as a string. Valid categories are: biolink:Disease, biolink:PhenotypicQuality, and biolink:Gene', 'default': 'biolink:Disease'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of search results to return.', 'default': 2}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['term']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'results': {'title': 'Results', 'type': 'array', 'items': {'$ref': '#/components/schemas/SearchResultItem'}, 'description': 'A list of SearchResultItem objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of search results available.'}}, 'required': ['results', 'total']}),\n",
      "    RestApiClient(allowlist=None, denylist=None, name='/disease-genes', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='disease-genes', description='Get a list of genes associated with a disease', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of genes associated with a disease', 'properties': {'disease_id': {'title': 'Disease Id', 'type': 'string', 'description': 'The ontology identifier of the disease.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['disease_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/GeneAssociation'}, 'description': 'The list of GeneAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of gene associations available.'}}, 'required': ['associations', 'total']}),\n",
      "    RestApiClient(allowlist=None, denylist=None, name='/disease-phenotypes', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='disease-phenotypes', description='Get a list of phenotypes associated with a disease', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of phenotypes associated with a disease', 'properties': {'disease_id': {'title': 'Disease Id', 'type': 'string', 'description': 'The ontology identifier of the disease.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results.', 'default': 1}}, 'required': ['disease_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/PhenotypeAssociation'}, 'description': 'The list of PhenotypeAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of phenotype associations available.'}}, 'required': ['associations', 'total']}),\n",
      "    RestApiClient(allowlist=None, denylist=None, name='/gene-diseases', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='gene-diseases', description='Get a list of diseases associated with a gene', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of diseases associated with a gene', 'properties': {'gene_id': {'title': 'Gene Id', 'type': 'string', 'description': 'The ontology identifier of the gene.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['gene_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/DiseaseAssociation'}, 'description': 'The list of DiseaseAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of disease associations available.'}}, 'required': ['associations', 'total']}),\n",
      "    RestApiClient(allowlist=None, denylist=None, name='/gene-phenotypes', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='gene-phenotypes', description='Get a list of phenotypes associated with a gene', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of phenotypes associated with a gene', 'properties': {'gene_id': {'title': 'Gene Id', 'type': 'string', 'description': 'The ontology identifier of the gene.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['gene_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/PhenotypeAssociation'}, 'description': 'The list of PhenotypeAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of phenotype associations available.'}}, 'required': ['associations', 'total']}),\n",
      "    RestApiClient(allowlist=None, denylist=None, name='/phenotype-diseases', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='phenotype-diseases', description='Get a list of diseases associated with a phenotype', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of diseases associated with a phenotype', 'properties': {'phenotype_id': {'title': 'Phenotype Id', 'type': 'string', 'description': 'The ontology identifier of the phenotype.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'default': 1}}, 'required': ['phenotype_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/DiseaseAssociation'}, 'description': 'The list of DiseaseAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of disease associations available.'}}, 'required': ['associations', 'total']}),\n",
      "    RestApiClient(allowlist=None, denylist=None, name='/phenotype-genes', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='phenotype-genes', description='Get a list of genes associated with a phenotype', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of genes associated with a phenotype', 'properties': {'phenotype_id': {'title': 'Phenotype Id', 'type': 'string', 'description': 'The ontology identifier of the phenotype.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['phenotype_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/GeneAssociation'}, 'description': 'The list of GeneAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of gene associations available.'}}, 'required': ['associations', 'total']})]\n"
     ]
    }
   ],
   "source": [
    "def extract_query_params(openapi_spec, path, method):\n",
    "    path_spec = openapi_spec[\"paths\"].get(path)\n",
    "    if not path_spec:\n",
    "        raise ValueError(f\"No path found for {path}\")\n",
    "\n",
    "    method_spec = path_spec.get(method.lower())\n",
    "    if not method_spec:\n",
    "        raise ValueError(f\"No method found for {method}\")\n",
    "    \n",
    "    title = openapi_spec['info']['title']\n",
    "    description = path_spec[method.lower()]['description']\n",
    "\n",
    "    query_params_spec = [param for param in method_spec.get('parameters', []) if param['in'] == 'query']\n",
    "\n",
    "    return {\n",
    "        \"$schema\": \"https://json-schema.org/draft/2019-09/schema\",\n",
    "        \"$id\": \"http://example.com/example.json\",\n",
    "        \"type\": \"object\",\n",
    "        \"default\": {},\n",
    "        \"title\": title,\n",
    "        \"description\": description,\n",
    "        \"properties\": {param['name']: param['schema'] for param in query_params_spec},\n",
    "        \"required\": [param['name'] for param in query_params_spec if param['required']]\n",
    "    }\n",
    "\n",
    "def extract_response_body(openapi_spec, path, method, status_code):\n",
    "    path_spec = openapi_spec[\"paths\"].get(path)\n",
    "    if not path_spec:\n",
    "        raise ValueError(f\"No path found for {path}\")\n",
    "\n",
    "    method_spec = path_spec.get(method.lower())\n",
    "    if not method_spec:\n",
    "        raise ValueError(f\"No method found for {method}\")\n",
    "\n",
    "    response_spec = method_spec['responses'].get(str(status_code))\n",
    "    if not response_spec:\n",
    "        raise ValueError(f\"No response found for status code {status_code}\")\n",
    "\n",
    "    title = openapi_spec['info']['title']\n",
    "\n",
    "    schema_ref = response_spec['content']['application/json']['schema']['$ref']\n",
    "    schema_name = schema_ref.split('/')[-1]\n",
    "    schema = openapi_spec['components']['schemas'].get(schema_name)\n",
    "\n",
    "    if not schema:\n",
    "        raise ValueError(f\"No schema found for {schema_name}\")\n",
    "\n",
    "    return {\n",
    "        \"$schema\": \"https://json-schema.org/draft/2019-09/schema\",\n",
    "        \"$id\": \"http://example.com/example.json\",\n",
    "        \"type\": \"object\",\n",
    "        \"default\": {},\n",
    "        \"title\": title,\n",
    "        \"properties\": schema['properties'],\n",
    "        \"required\": schema.get('required', [])\n",
    "    }\n",
    "\n",
    "toolset = []\n",
    "\n",
    "spec = json.load(open(\"openapi.json\"))\n",
    "for endpoint in spec[\"paths\"]:\n",
    "    tool_get_query_schema = extract_query_params(spec, endpoint, \"GET\")\n",
    "    tool_get_response_schema = extract_response_body(spec, endpoint, \"GET\", 200)\n",
    "\n",
    "    endpoint_tool = RestApiClient(\n",
    "        base_url = \"http://localhost:3434\",\n",
    "        # remove / prefix from endpoint\n",
    "        path = endpoint[1:], \n",
    "        name = endpoint,\n",
    "        description = tool_get_query_schema['description'],\n",
    "        request_query_params_schema = tool_get_query_schema,\n",
    "        response_body_schema = tool_get_response_schema)\n",
    "\n",
    "    toolset.append(endpoint_tool)\n",
    "\n",
    "\n",
    "pp.pprint(toolset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "34053540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/12/23 21:50:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Task fd739d212cba4fd3a4c839c41765b3cf                                                 \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Input: What can you tell me about Cystic Fibrosis?                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/12/23 21:50:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Task fd739d212cba4fd3a4c839c41765b3cf                                                 \n",
       "\u001b[2;36m                    \u001b[0m         Input: What can you tell me about Cystic Fibrosis?                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:error_code=None error_message=\"0 is less than the minimum of 1 - 'max_tokens'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 0 failed: 0 is less than the minimum of 1 - 'max_tokens'\n",
      "Retrying in 1 seconds\n",
      "INFO:openai:error_code=None error_message=\"0 is less than the minimum of 1 - 'max_tokens'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 1 failed: 0 is less than the minimum of 1 - 'max_tokens'\n",
      "Retrying in 1 seconds\n",
      "INFO:openai:error_code=None error_message=\"0 is less than the minimum of 1 - 'max_tokens'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 2 failed: 0 is less than the minimum of 1 - 'max_tokens'\n",
      "Retrying in 1 seconds\n",
      "INFO:openai:error_code=None error_message=\"0 is less than the minimum of 1 - 'max_tokens'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 3 failed: 0 is less than the minimum of 1 - 'max_tokens'\n",
      "Retrying in 1 seconds\n",
      "INFO:openai:error_code=None error_message=\"0 is less than the minimum of 1 - 'max_tokens'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 4 failed: 0 is less than the minimum of 1 - 'max_tokens'\n",
      "Retrying in 1 seconds\n",
      "INFO:openai:error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-GpIp4LxR4sdHH069D9sFP5vp on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 5 failed: Rate limit reached for default-gpt-4 in organization org-GpIp4LxR4sdHH069D9sFP5vp on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "Retrying in 1 seconds\n",
      "INFO:openai:error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-GpIp4LxR4sdHH069D9sFP5vp on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 6 failed: Rate limit reached for default-gpt-4 in organization org-GpIp4LxR4sdHH069D9sFP5vp on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "Retrying in 1 seconds\n",
      "INFO:openai:error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-GpIp4LxR4sdHH069D9sFP5vp on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 7 failed: Rate limit reached for default-gpt-4 in organization org-GpIp4LxR4sdHH069D9sFP5vp on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "Retrying in 1 seconds\n",
      "INFO:openai:error_code=None error_message=\"0 is less than the minimum of 1 - 'max_tokens'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:PromptDriver.run attempt 8 failed: 0 is less than the minimum of 1 - 'max_tokens'\n",
      "Retrying in 1 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/12/23 21:51:11] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Task fd739d212cba4fd3a4c839c41765b3cf                                                 \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> is less than the minimum of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> - <span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens'</span>                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:                                                    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/griptape/tasks/base_task.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>, in execute        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             self.output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.run</span><span style=\"font-weight: bold\">()</span>                                                          \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                           ^^^^^^^^^^                                                          \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/griptape/tasks/toolkit_task.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52</span>, in run          \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.active_driver</span><span style=\"font-weight: bold\">()</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.run</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">value</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.structure.to_prompt_string</span><span style=\"font-weight: bold\">(</span>self<span style=\"font-weight: bold\">))</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.to_text</span><span style=\"font-weight: bold\">()</span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^             \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/griptape/drivers/prompt/base_prompt_driver.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         in run                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             raise e                                                                           \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/griptape/drivers/prompt/base_prompt_driver.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         in run                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.try_run</span><span style=\"font-weight: bold\">(</span>**kwargs<span style=\"font-weight: bold\">)</span>                                                     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                    ^^^^^^^^^^^^^^^^^^^^^^                                                     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/griptape/drivers/prompt/openai_prompt_driver.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         in try_run                                                                            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.__run_chat</span><span style=\"font-weight: bold\">(</span>value<span style=\"font-weight: bold\">)</span>                                                     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                    ^^^^^^^^^^^^^^^^^^^^^^                                                     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/griptape/drivers/prompt/openai_prompt_driver.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>,\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         in __run_chat                                                                         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             result = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">openai.ChatCompletion.create</span><span style=\"font-weight: bold\">(</span>                                            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/openai/api_resources/chat_completion.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>, in     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         create                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">super</span><span style=\"font-weight: bold\">()</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.create</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>                                            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\"</span>,    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">153</span>, in create                                                                   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             response, _, api_key = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">requestor.request</span><span style=\"font-weight: bold\">(</span>                                         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                    ^^^^^^^^^^^^^^^^^^                                         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/openai/api_requestor.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">230</span>, in request            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             resp, got_stream = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._interpret_response</span><span style=\"font-weight: bold\">(</span>result, stream<span style=\"font-weight: bold\">)</span>                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/openai/api_requestor.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">624</span>, in _interpret_response\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._interpret_response_line</span><span style=\"font-weight: bold\">(</span>                                                    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           File                                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ib/python3.11/site-packages/openai/api_requestor.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">687</span>, in                    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         _interpret_response_line                                                              \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>             raise <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.handle_error_response</span><span style=\"font-weight: bold\">(</span>                                                 \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         openai.error.InvalidRequestError: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> is less than the minimum of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> - <span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens'</span>      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/12/23 21:51:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Task fd739d212cba4fd3a4c839c41765b3cf                                                 \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m is less than the minimum of \u001b[1;36m1\u001b[0m - \u001b[32m'max_tokens'\u001b[0m                                        \n",
       "\u001b[2;36m                    \u001b[0m         Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:                                                    \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/griptape/tasks/base_task.py\"\u001b[0m, line \u001b[1;36m110\u001b[0m, in execute        \n",
       "\u001b[2;36m                    \u001b[0m             self.output = \u001b[1;35mself.run\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                                          \n",
       "\u001b[2;36m                    \u001b[0m                           ^^^^^^^^^^                                                          \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/griptape/tasks/toolkit_task.py\"\u001b[0m, line \u001b[1;36m52\u001b[0m, in run          \n",
       "\u001b[2;36m                    \u001b[0m             \u001b[1;35mself.active_driver\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.run\u001b[0m\u001b[1m(\u001b[0m\u001b[33mvalue\u001b[0m=\u001b[1;35mself\u001b[0m\u001b[1;35m.structure.to_prompt_string\u001b[0m\u001b[1m(\u001b[0mself\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.to_text\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m   \n",
       "\u001b[2;36m                    \u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^             \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/griptape/drivers/prompt/base_prompt_driver.py\"\u001b[0m, line \u001b[1;36m31\u001b[0m,  \n",
       "\u001b[2;36m                    \u001b[0m         in run                                                                                \n",
       "\u001b[2;36m                    \u001b[0m             raise e                                                                           \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/griptape/drivers/prompt/base_prompt_driver.py\"\u001b[0m, line \u001b[1;36m24\u001b[0m,  \n",
       "\u001b[2;36m                    \u001b[0m         in run                                                                                \n",
       "\u001b[2;36m                    \u001b[0m             return \u001b[1;35mself.try_run\u001b[0m\u001b[1m(\u001b[0m**kwargs\u001b[1m)\u001b[0m                                                     \n",
       "\u001b[2;36m                    \u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^                                                     \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/griptape/drivers/prompt/openai_prompt_driver.py\"\u001b[0m, line \u001b[1;36m32\u001b[0m,\n",
       "\u001b[2;36m                    \u001b[0m         in try_run                                                                            \n",
       "\u001b[2;36m                    \u001b[0m             return \u001b[1;35mself.__run_chat\u001b[0m\u001b[1m(\u001b[0mvalue\u001b[1m)\u001b[0m                                                     \n",
       "\u001b[2;36m                    \u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^                                                     \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/griptape/drivers/prompt/openai_prompt_driver.py\"\u001b[0m, line \u001b[1;36m37\u001b[0m,\n",
       "\u001b[2;36m                    \u001b[0m         in __run_chat                                                                         \n",
       "\u001b[2;36m                    \u001b[0m             result = \u001b[1;35mopenai.ChatCompletion.create\u001b[0m\u001b[1m(\u001b[0m                                            \n",
       "\u001b[2;36m                    \u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                            \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/openai/api_resources/chat_completion.py\"\u001b[0m, line \u001b[1;36m25\u001b[0m, in     \n",
       "\u001b[2;36m                    \u001b[0m         create                                                                                \n",
       "\u001b[2;36m                    \u001b[0m             return \u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.create\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                                            \n",
       "\u001b[2;36m                    \u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                                            \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\"\u001b[0m,    \n",
       "\u001b[2;36m                    \u001b[0m         line \u001b[1;36m153\u001b[0m, in create                                                                   \n",
       "\u001b[2;36m                    \u001b[0m             response, _, api_key = \u001b[1;35mrequestor.request\u001b[0m\u001b[1m(\u001b[0m                                         \n",
       "\u001b[2;36m                    \u001b[0m                                    ^^^^^^^^^^^^^^^^^^                                         \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/openai/api_requestor.py\"\u001b[0m, line \u001b[1;36m230\u001b[0m, in request            \n",
       "\u001b[2;36m                    \u001b[0m             resp, got_stream = \u001b[1;35mself._interpret_response\u001b[0m\u001b[1m(\u001b[0mresult, stream\u001b[1m)\u001b[0m                       \n",
       "\u001b[2;36m                    \u001b[0m                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                       \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/openai/api_requestor.py\"\u001b[0m, line \u001b[1;36m624\u001b[0m, in _interpret_response\n",
       "\u001b[2;36m                    \u001b[0m             \u001b[1;35mself._interpret_response_line\u001b[0m\u001b[1m(\u001b[0m                                                    \n",
       "\u001b[2;36m                    \u001b[0m           File                                                                                \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"/Users/oneils/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-wLCrjSQa-py3.11/l\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mib/python3.11/site-packages/openai/api_requestor.py\"\u001b[0m, line \u001b[1;36m687\u001b[0m, in                    \n",
       "\u001b[2;36m                    \u001b[0m         _interpret_response_line                                                              \n",
       "\u001b[2;36m                    \u001b[0m             raise \u001b[1;35mself.handle_error_response\u001b[0m\u001b[1m(\u001b[0m                                                 \n",
       "\u001b[2;36m                    \u001b[0m         openai.error.InvalidRequestError: \u001b[1;36m0\u001b[0m is less than the minimum of \u001b[1;36m1\u001b[0m - \u001b[32m'max_tokens'\u001b[0m      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ToolkitTask(id='fd739d212cba4fd3a4c839c41765b3cf', state=<State.FINISHED: 3>, parent_ids=[], child_ids=[], structure=Pipeline(id='cfe8f2b5683c4a31ad22b33aa86cc387', prompt_driver=OpenAiPromptDriver(max_retries=8, retry_delay=1, temperature=0.1, api_type='open_ai', api_version=None, api_base='https://api.openai.com/v1', api_key='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', organization=None, model='gpt-4', tokenizer=TiktokenTokenizer(stop_sequence='Observation:', model='gpt-4'), user=''), rulesets=[], tasks=[...], custom_logger=None, logger_level=20, _execution_args=(), _logger=<Logger griptape-flow (INFO)>, memory=ConversationMemory(type='ConversationMemory', driver=None, runs=[Run(id='682e757c18d94a9286620762d0dcb399', input='What can you tell me about Cystic Fibrosis?', output=\"0 is less than the minimum of 1 - 'max_tokens'\")], structure=...), autoprune_memory=True), prompt_template='{{ args[0] }}', context={}, driver=None, output=ErrorArtifact(type='ErrorArtifact', value=\"0 is less than the minimum of 1 - 'max_tokens'\"), tools=[RestApiClient(allowlist=None, denylist=None, name='/search', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='search', description='Search for entities in the Monarch knowledge graph', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Search for entities in the Monarch knowledge graph', 'properties': {'term': {'title': 'Term', 'type': 'string', 'description': 'The ontology term to search for.'}, 'category': {'title': 'Category', 'type': 'string', 'description': 'A single category to search within as a string. Valid categories are: biolink:Disease, biolink:PhenotypicQuality, and biolink:Gene', 'default': 'biolink:Disease'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of search results to return.', 'default': 2}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['term']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'results': {'title': 'Results', 'type': 'array', 'items': {'$ref': '#/components/schemas/SearchResultItem'}, 'description': 'A list of SearchResultItem objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of search results available.'}}, 'required': ['results', 'total']}), RestApiClient(allowlist=None, denylist=None, name='/disease-genes', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='disease-genes', description='Get a list of genes associated with a disease', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of genes associated with a disease', 'properties': {'disease_id': {'title': 'Disease Id', 'type': 'string', 'description': 'The ontology identifier of the disease.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['disease_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/GeneAssociation'}, 'description': 'The list of GeneAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of gene associations available.'}}, 'required': ['associations', 'total']}), RestApiClient(allowlist=None, denylist=None, name='/disease-phenotypes', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='disease-phenotypes', description='Get a list of phenotypes associated with a disease', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of phenotypes associated with a disease', 'properties': {'disease_id': {'title': 'Disease Id', 'type': 'string', 'description': 'The ontology identifier of the disease.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results.', 'default': 1}}, 'required': ['disease_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/PhenotypeAssociation'}, 'description': 'The list of PhenotypeAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of phenotype associations available.'}}, 'required': ['associations', 'total']}), RestApiClient(allowlist=None, denylist=None, name='/gene-diseases', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='gene-diseases', description='Get a list of diseases associated with a gene', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of diseases associated with a gene', 'properties': {'gene_id': {'title': 'Gene Id', 'type': 'string', 'description': 'The ontology identifier of the gene.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['gene_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/DiseaseAssociation'}, 'description': 'The list of DiseaseAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of disease associations available.'}}, 'required': ['associations', 'total']}), RestApiClient(allowlist=None, denylist=None, name='/gene-phenotypes', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='gene-phenotypes', description='Get a list of phenotypes associated with a gene', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of phenotypes associated with a gene', 'properties': {'gene_id': {'title': 'Gene Id', 'type': 'string', 'description': 'The ontology identifier of the gene.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['gene_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/PhenotypeAssociation'}, 'description': 'The list of PhenotypeAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of phenotype associations available.'}}, 'required': ['associations', 'total']}), RestApiClient(allowlist=None, denylist=None, name='/phenotype-diseases', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='phenotype-diseases', description='Get a list of diseases associated with a phenotype', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of diseases associated with a phenotype', 'properties': {'phenotype_id': {'title': 'Phenotype Id', 'type': 'string', 'description': 'The ontology identifier of the phenotype.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'default': 1}}, 'required': ['phenotype_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/DiseaseAssociation'}, 'description': 'The list of DiseaseAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of disease associations available.'}}, 'required': ['associations', 'total']}), RestApiClient(allowlist=None, denylist=None, name='/phenotype-genes', memory={}, install_dependencies_on_init=True, dependencies_install_directory=None, verbose=False, artifacts=[], base_url='http://localhost:3434', path='phenotype-genes', description='Get a list of genes associated with a phenotype', request_path_params_schema=None, request_query_params_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'description': 'Get a list of genes associated with a phenotype', 'properties': {'phenotype_id': {'title': 'Phenotype Id', 'type': 'string', 'description': 'The ontology identifier of the phenotype.'}, 'limit': {'title': 'Limit', 'type': 'integer', 'description': 'The maximum number of associations to return.', 'default': 10}, 'offset': {'title': 'Offset', 'type': 'integer', 'description': 'Offset for pagination of results', 'default': 1}}, 'required': ['phenotype_id']}, request_body_schema=None, response_body_schema={'$schema': 'https://json-schema.org/draft/2019-09/schema', '$id': 'http://example.com/example.json', 'type': 'object', 'default': {}, 'title': 'Monarch', 'properties': {'associations': {'title': 'Associations', 'type': 'array', 'items': {'$ref': '#/components/schemas/GeneAssociation'}, 'description': 'The list of GeneAssociation objects.'}, 'total': {'title': 'Total', 'type': 'integer', 'description': 'The total number of gene associations available.'}}, 'required': ['associations', 'total']})], max_subtasks=20, _subtasks=[])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    memory=ConversationMemory(),\n",
    "    prompt_driver=OpenAiPromptDriver(\n",
    "        temperature=0.1,\n",
    "        model = \"gpt-4\"\n",
    "    ), \n",
    ")\n",
    "\n",
    "pipeline.add_tasks(\n",
    "    ToolkitTask(\n",
    "        \"{{ args[0] }}\",\n",
    "        tools=toolset[:3],\n",
    "    )\n",
    ")\n",
    "\n",
    "pipeline.run(\"What can you tell me about Cystic Fibrosis?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "310eb340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What phenotypes are associated with diabetes?\n",
      "A: There are no phenotypes directly associated with diabetes mellitus in the database I have access to. However, diabetes mellitus is a complex disease with various symptoms and complications that can be considered as phenotypes.\n"
     ]
    }
   ],
   "source": [
    "print(utils.Conversation(pipeline.memory))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
