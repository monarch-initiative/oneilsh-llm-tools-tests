{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e214fb35",
   "metadata": {},
   "source": [
    "A small DIY agent that can call a limited subset of python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14370082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional\n",
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4cd1e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \" I'm doing well, thank you. How are you? I hope you are as well.\", 'conversation': {'generated_responses': [\" I'm doing well, thank you. How are you? I hope you are as well.\"], 'past_user_inputs': ['<human>How are you today?\\n<bot>:']}}\n"
     ]
    }
   ],
   "source": [
    "def new_hf_chat_generic(inputs):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/facebook/blenderbot-400M-distill\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.environ['HUGGINGFACE_API_KEY']}\"}\n",
    "    \n",
    "    payload = {\"inputs\": inputs}\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "print(new_hf_chat_generic(\"<human>How are you today?\\n<bot>:\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e244bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that makes a call to the openai API, taking a system message (str) and user message (str)\n",
    "# and returning a response (str)\n",
    "# it also calls the maybe_eval_last_message() function to see if the LLM is trying to call a tool (see below)\n",
    "def start_new_chat_generic(system_message: str, user_message: str, model: str = \"gpt-3.5-turbo\") -> List[Dict[str, str]]:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "              model=model,\n",
    "              temperature = 0,\n",
    "              messages=messages)\n",
    "\n",
    "    response_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    response_role = response[\"choices\"][0][\"message\"][\"role\"]\n",
    "    messages.append({\"role\": response_role, \"content\": response_content})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45ff3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continues a chat returned from start_new_chat() or continue_chat(), \n",
    "# taking the current conversation and a new user message\n",
    "# calls the maybe_eval_last_message() function to see if the LLM is trying to call a tool (see below)\n",
    "def continue_chat(messages: List[Dict[str, str]], new_user_message: str, model: str = \"gpt-3.5-turbo\") -> List[Dict[str, str]]:\n",
    "    messages.append({\"role\": \"user\", \"content\": new_user_message})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "              model=model,\n",
    "              temperature = 0,\n",
    "              messages=messages)\n",
    "\n",
    "    msg_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    msg_role = response[\"choices\"][0][\"message\"][\"role\"]\n",
    "            \n",
    "    messages.append({\"role\": msg_role, \"content\": msg_content})\n",
    "    messages = maybe_eval_last_message(messages)\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5de2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a class defininng a safe set of callable functions\n",
    "# (note: also inludes a set of safe functions defined by asteval, including abs(), random.choice(), etc.)\n",
    "# see example usage below\n",
    "from asteval import Interpreter\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "\n",
    "\n",
    "class SafeEval:\n",
    "    def __init__(self):\n",
    "        self.interpreter = Interpreter()\n",
    "        self._add_methods()\n",
    "\n",
    "    def _add_methods(self):\n",
    "        # Get all methods of the class\n",
    "        methods = [func for func in dir(self) if callable(getattr(self, func)) and not func.startswith(\"_\")]\n",
    "        # Add them to the interpreter's symbol table\n",
    "        for method in methods:\n",
    "            self.interpreter.symtable[method] = getattr(self, method)\n",
    "\n",
    "    def evaluate(self, expression: str) -> str:\n",
    "        return self.interpreter(expression)\n",
    "    \n",
    "    def echo(self, x):\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    def sum(self, a, b):\n",
    "        return a + b\n",
    "\n",
    "    def product(self, a, b):\n",
    "        return a * b\n",
    "\n",
    "    def time(self):\n",
    "        now = datetime.now()\n",
    "\n",
    "        # Format the datetime object\n",
    "        formatted_now = now.strftime(\"%m/%d/%y %H:%M\")\n",
    "\n",
    "        return formatted_now\n",
    "\n",
    "    def entropy(self, lst):\n",
    "        # Compute frequencies\n",
    "        counter = Counter(lst)\n",
    "\n",
    "        # Compute probabilities\n",
    "        probabilities = [count/len(lst) for count in counter.values()]\n",
    "\n",
    "        # Compute entropy\n",
    "        return -sum(p * log2(p) for p in probabilities)\n",
    "\n",
    "\n",
    "\n",
    "# # example usage:\n",
    "# # Create a SafeEval object\n",
    "# safe_eval = SafeEval()\n",
    "\n",
    "# # Test the methods\n",
    "# #print(safe_eval.evaluate('sum(5, product(2, abs(-3)))'))  # prints 11\n",
    "# print(safe_eval.evaluate('normalized_entropy([\"apple\"] * 4 + [\"pear\"] * 2 + [\"peach\"] * 10)'))  # prints 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0517cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs snippes of python code through the safe evaluator, see example usage below\n",
    "def replace_eval_tags(text, safe_eval):\n",
    "    # Regular expression pattern for <eval> tags\n",
    "    pattern = re.compile(r'<eval>(.*?)</eval>')\n",
    "\n",
    "    results = []\n",
    "    # Function to replace each match with its evaluated result\n",
    "    def replace_with_eval(match):\n",
    "        code = match.group(1)  # Extract the code string from the match\n",
    "        results.append(safe_eval.evaluate(code))  # Evaluate the code\n",
    "\n",
    "    # Replace all <eval> tags in the text\n",
    "    pattern.sub(replace_with_eval, text)\n",
    "    return results\n",
    "\n",
    "# # example usage:\n",
    "# # Test the function\n",
    "# safe_eval = SafeEval()\n",
    "# text = \"I need to compute <eval>sum(4, 5)</eval> and <eval>2 + 3</eval>.\"\n",
    "# print(replace_eval_tags(text, safe_eval))  # prints [9, 5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf1a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks to see if the last message needs interpretation\n",
    "safe_eval = SafeEval()\n",
    "def maybe_eval_last_message(messages):\n",
    "    last_message = messages[-1][\"content\"]\n",
    "    computations = replace_eval_tags(last_message, safe_eval)\n",
    "    if len(computations) > 0:\n",
    "        # once it tried asking a following question along with a set of computations, and when it got the\n",
    "        # answer back of just the computation results got confused. \n",
    "        result = \"RESULT: \" + json.dumps(computations) # + \"(Warning: other text ignored)\"\n",
    "        return continue_chat(messages, result)\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401a95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def new_chat_safeeval_agent(user_message: str, model: str = \"gpt-3.5-turbo\") -> List[Dict[str, str]]:\n",
    "    system_prompt = \"\"\"You are a helpful assistant with the ability to have thoughts, and those \n",
    "    thoughts can execute a limited subset of Python code by wrapping it in <eval></eval> tags.\"\"\"\n",
    "\n",
    "    first_user_prompt = \"\"\"You are a helpful assistant with the ability to use tools with \n",
    "    the help of your user. These tools allow you to execute a subset of Python code by wrapping it \n",
    "    in <eval></eval> tags. \n",
    "    \n",
    "    If you use one or more tool computations, the user will execute them, and provide the results\n",
    "    as a JSON-formatted list. You should then finish your response based on the computed answer.\n",
    "\n",
    "    EXAMPLE:\n",
    "    user: What is the sum of 4 and 5? What is the sum of 2 and 3? What is the product of the prior two answers?\n",
    "    assistant: I need to compute <eval>sum(4, 5)</eval>, <eval>sum(2, 3)</eval>, and <eval>product(sum(3, 4), sum(2, 3))</eval>\n",
    "    user: RESULT: [9, 6, 54]\n",
    "    assistant: The sum of 4 and 5 is 9, the sum of 2 and 3 is 6, and the product of these sums is 54.\n",
    "    \n",
    "    EXAMPLE:\n",
    "    user: A container has 4 apples, 2 pears, and 10 peaches. What is its entropy?\n",
    "    assistant: I need to compute <eval>normalized_entropy([\"apple\"] * 4 + [\"pear\"] * 2 + [\"peach\"] * 10)</eval>\n",
    "    user: RESULT: [0.8194483718728035]\n",
    "    assistant: The entropy is approximately 0.819 <with other information or interpretation as necessary>\n",
    "\n",
    "    The following functions are available:\n",
    "    - sum(a, b): returns the sum of numbers a and b\n",
    "    - product(a, b): returns the product of the numbers a and b\n",
    "    - entropy(items: List[str]): returns the entropy of a given list of strings\n",
    "    - echo(x): returns x itself, useful for debugging\n",
    "    - time(): return the current time in MM/DD/YY HH:MM format\n",
    "\n",
    "    You should always prefer to use listed tools before computing an answer yourself. Don't repeat yourself.\n",
    "    \n",
    "    Confirm by computing the current time.\n",
    "    \"\"\"\n",
    "    #assistant: I have computed the answer. The sum of 4 and 5 is 9, the sum of 2 and 3 is 6, and the product of these is 54.\n",
    "\n",
    "    messages = start_new_chat_generic(system_prompt, first_user_prompt, model = model)\n",
    "    messages = maybe_eval_last_message(messages)\n",
    "    messages = continue_chat(messages, user_message)\n",
    "\n",
    "    return messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95df73e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant with the ability to have thoughts, '\n",
      "             'and those \\n'\n",
      "             '    thoughts can execute a limited subset of Python code by '\n",
      "             'wrapping it in <eval></eval> tags.',\n",
      "  'role': 'system'},\n",
      " {'content': 'You are a helpful assistant with the ability to use tools with \\n'\n",
      "             '    the help of your user. These tools allow you to execute a '\n",
      "             'subset of Python code by wrapping it \\n'\n",
      "             '    in <eval></eval> tags. \\n'\n",
      "             '    \\n'\n",
      "             '    If you use one or more tool computations, the user will '\n",
      "             'execute them, and provide the results\\n'\n",
      "             '    as a JSON-formatted list. You should then finish your '\n",
      "             'response based on the computed answer.\\n'\n",
      "             '\\n'\n",
      "             '    EXAMPLE:\\n'\n",
      "             '    user: What is the sum of 4 and 5? What is the sum of 2 and '\n",
      "             '3? What is the product of the prior two answers?\\n'\n",
      "             '    assistant: I need to compute <eval>sum(4, 5)</eval>, '\n",
      "             '<eval>sum(2, 3)</eval>, and <eval>product(sum(3, 4), sum(2, '\n",
      "             '3))</eval>\\n'\n",
      "             '    user: RESULT: [9, 6, 54]\\n'\n",
      "             '    assistant: The sum of 4 and 5 is 9, the sum of 2 and 3 is 6, '\n",
      "             'and the product of these sums is 54.\\n'\n",
      "             '    \\n'\n",
      "             '    EXAMPLE:\\n'\n",
      "             '    user: A container has 4 apples, 2 pears, and 10 peaches. '\n",
      "             'What is its entropy?\\n'\n",
      "             '    assistant: I need to compute '\n",
      "             '<eval>normalized_entropy([\"apple\"] * 4 + [\"pear\"] * 2 + '\n",
      "             '[\"peach\"] * 10)</eval>\\n'\n",
      "             '    user: RESULT: [0.8194483718728035]\\n'\n",
      "             '    assistant: The entropy is approximately 0.819 <with other '\n",
      "             'information or interpretation as necessary>\\n'\n",
      "             '\\n'\n",
      "             '    The following functions are available:\\n'\n",
      "             '    - sum(a, b): returns the sum of numbers a and b\\n'\n",
      "             '    - product(a, b): returns the product of the numbers a and b\\n'\n",
      "             '    - entropy(items: List[str]): returns the entropy of a given '\n",
      "             'list of strings\\n'\n",
      "             '    - echo(x): returns x itself, useful for debugging\\n'\n",
      "             '    - time(): return the current time in MM/DD/YY HH:MM format\\n'\n",
      "             '\\n'\n",
      "             '    You should always prefer to use listed tools before '\n",
      "             \"computing an answer yourself. Don't repeat yourself.\\n\"\n",
      "             '    \\n'\n",
      "             '    Confirm by computing the current time.\\n'\n",
      "             '    ',\n",
      "  'role': 'user'},\n",
      " {'content': 'I can confirm the current time by computing <eval>time()</eval>.',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'RESULT: [\"06/06/23 00:58\"]', 'role': 'user'},\n",
      " {'content': 'The current time is 06/06/23 00:58. How can I assist you '\n",
      "             'further?',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'What is the entropy of a standard scrabble set?', 'role': 'user'},\n",
      " {'content': 'I need to compute <eval>entropy([\"E\"] * 12 + [\"A\"] * 9 + [\"I\"] * '\n",
      "             '9 + [\"O\"] * 8 + [\"N\"] * 6 + [\"R\"] * 6 + [\"T\"] * 6 + [\"L\"] * 4 + '\n",
      "             '[\"S\"] * 4 + [\"U\"] * 4 + [\"D\"] * 4 + [\"G\"] * 3 + [\"B\"] * 2 + '\n",
      "             '[\"C\"] * 2 + [\"M\"] * 2 + [\"P\"] * 2 + [\"F\"] * 2 + [\"H\"] * 2 + '\n",
      "             '[\"V\"] * 2 + [\"W\"] * 2 + [\"Y\"] * 2 + [\"K\"] + [\"J\"] + [\"X\"] + '\n",
      "             '[\"Q\"] + [\"Z\"])</eval>',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'RESULT: [4.315093389525824]', 'role': 'user'},\n",
      " {'content': 'The entropy of a standard scrabble set is approximately 4.315.',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "convo = new_chat_safeeval_agent(\"What is the entropy of a standard scrabble set?\")\n",
    "pp.pprint(convo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
