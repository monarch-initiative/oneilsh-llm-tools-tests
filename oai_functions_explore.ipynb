{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import dotenv\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a couple of functions to call later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collatz_count(n: int) -> int:\n",
    "    count = 0\n",
    "    while n > 1:\n",
    "        if n % 2 == 0:\n",
    "            n = n // 2\n",
    "        else:\n",
    "            n = 3*n + 1\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def fibonacci(n: int) -> int:\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we send the usual, a system message (which seems to not be required, the demo from openai didn't include one), a user question, but **also** a list of functions that can be called and a schema for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OpenAIObject chat.completion id=chatcmpl-7RNqc24ZwCCY6J01OszvHJ0zrtvqs at 0x1148f5d90> JSON: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"function_call\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"arguments\": \"{\\n  \\\"n\\\": 7\\n}\",\n",
      "          \"name\": \"fibonacci\"\n",
      "        },\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1686760882,\n",
      "  \"id\": \"chatcmpl-7RNqc24ZwCCY6J01OszvHJ0zrtvqs\",\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 16,\n",
      "    \"prompt_tokens\": 125,\n",
      "    \"total_tokens\": 141\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"What's the 7th Fibonacci number?\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-0613\", temperature = 0, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": question}],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"collatz_count\",\n",
    "            \"description\": \"Counts how many steps it takes for a number to reach 1 in the Collatz sequence.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"n\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The index of the item in the Collatz sequence to get.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"n\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fibonacci\",\n",
    "            \"description\": \"Gets the nth number in the Fibonacci sequence.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"n\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The index of the item in the Fibonacci sequence to get.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"n\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "\n",
    "pp.pprint(response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note* that this returned `null` in the `\"content\"` which usually holds the model response, instead there's a `\"function_call\"` response with a JSON string for the function name and args to call. (I've seen the model return info in the content as well though when asking tricky questions.)\n",
    "\n",
    "So let's extract the info and make the call. Notice that we now include a new message with a new role type of `\"function\"` and a `\"name\"` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages:\n",
      "[   {'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      "    {'content': \"What's the 7th Fibonacci number?\", 'role': 'user'},\n",
      "    <OpenAIObject at 0x1148f5c10> JSON: {\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"arguments\": \"{\\n  \\\"n\\\": 7\\n}\",\n",
      "    \"name\": \"fibonacci\"\n",
      "  },\n",
      "  \"role\": \"assistant\"\n",
      "},\n",
      "    {'content': '21', 'name': 'fibonacci', 'role': 'function'}]\n",
      "\n",
      "\n",
      "Response:\n",
      "<OpenAIObject chat.completion id=chatcmpl-7RNt8eqTrCmvsZYclOL8OV5NOb7F2 at 0x114628bf0> JSON: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The 7th Fibonacci number is 21.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1686761038,\n",
      "  \"id\": \"chatcmpl-7RNt8eqTrCmvsZYclOL8OV5NOb7F2\",\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 51,\n",
      "    \"total_tokens\": 61\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "if message.get(\"function_call\"):\n",
    "    # extract the function name the model wants to call\n",
    "    function_name = message[\"function_call\"][\"name\"]\n",
    "    # extract the params JSON (NB the response from the model may not be valid JSON)\n",
    "    arguments = json.loads(message[\"function_call\"][\"arguments\"])\n",
    "\n",
    "    # lookup the function in the global namespace from the name\n",
    "    if function_name in globals():\n",
    "        function = globals()[function_name]\n",
    "    else:\n",
    "        raise ValueError(f\"Function {function_name} not found.\")\n",
    "\n",
    "    # call the function with the arguments\n",
    "    function_response = function(**arguments)\n",
    "\n",
    "    # return the function result to the model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        message,\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": f\"{function_response}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    print(\"Messages:\")\n",
    "    pp.pprint(messages)\n",
    "\n",
    "    # Step 4, send model the info on the function call and function response\n",
    "    second_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-0613\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\nResponse:\")\n",
    "    pp.pprint(second_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This setup appears to only allow the model to call a single function at a time with no planning, though this could be done ala langchain with agents. (Change the question to ask two questions to see this.)\n",
    "\n",
    "On the other hand, this model must be fine-tuned to produce function calls in that format, so perhaps it will do better at embedding them in regular output. Here's a quick test of that, though using an example that calls the same functions as basically cheating, we'll need to add some other functions to test with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OpenAIObject chat.completion id=chatcmpl-7RO6gRVPbpyO6AMkgcJngtYzIu5iF at 0x1148f5bb0> JSON: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"I need to call the following functions:\\n<eval>\\n[\\n    {\\n        \\\"name\\\": \\\"fibonacci\\\",\\n        \\\"parameters\\\": {\\n            \\\"n\\\": 5\\n        }\\n    },\\n    {\\n        \\\"name\\\": \\\"collatz_count\\\",\\n        \\\"parameters\\\": {\\n            \\\"n\\\": 56\\n        }\\n    },\\n    {\\n        \\\"name\\\": \\\"collatz_count\\\",\\n        \\\"parameters\\\": {\\n            \\\"n\\\": {\\n                \\\"function_call\\\": {\\n                    \\\"name\\\": \\\"fibonacci\\\",\\n                    \\\"parameters\\\": { \\n                        \\\"n\\\": 8\\n                    }\\n                }\\n            }\\n        }\\n    }\\n]\\n</eval>\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1686761878,\n",
      "  \"id\": \"chatcmpl-7RO6gRVPbpyO6AMkgcJngtYzIu5iF\",\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 128,\n",
      "    \"prompt_tokens\": 397,\n",
      "    \"total_tokens\": 525\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"What's the 5th Fibonacci number? What's the Collatz number of 56? What is the Collatz number of the 8th Fibonacci number?\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-0613\", temperature = 0, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \n",
    "            \"\"\"\n",
    "            You may call multiple functions in a single request by returning a list of function names and parameters, in JSON format, wrapped in <eval></eval> tags.\n",
    "            You can also nest function calls by setting the value of a parameter to an object with key \"function_call\".\n",
    "            \n",
    "            Example:\n",
    "            User: call the function \"collatz_count\" with the parameter \"n\" set to 27, the function \"fibonacci\" with \"n\" set to 16, and the \"collatz_count\" of the 12th Fibonacci number, you would send the following:\n",
    "            Assistant: I need to call the following functions:\n",
    "                <eval>\n",
    "                [\n",
    "                        {\n",
    "                            \"name\": \"collatz_count\",\n",
    "                            \"parameters\": {\n",
    "                                \"n\": 27\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"fibonacci\",\n",
    "                            \"parameters\": {\n",
    "                                \"n\": 16\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"collatz_count\",\n",
    "                            \"parameters\": {\n",
    "                                \"n\": {\n",
    "                                    \"function_call\": {\n",
    "                                        \"name\": \"fibonacci\",\n",
    "                                        \"parameters\": { \n",
    "                                            \"n\": 12\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                </eval>\n",
    "            \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": question}],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"collatz_count\",\n",
    "            \"description\": \"Counts how many steps it takes for a number to reach 1 in the Collatz sequence.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"n\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The index of the item in the Collatz sequence to get.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"n\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fibonacci\",\n",
    "            \"description\": \"Gets the nth number in the Fibonacci sequence.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"n\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The index of the item in the Fibonacci sequence to get.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"n\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call=\"auto\", # what happens if we disable function calling for this kind of query? Does it still pay attention to the function schemas?\n",
    ")\n",
    "\n",
    "pp.pprint(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-tools-explore-wLCrjSQa-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
